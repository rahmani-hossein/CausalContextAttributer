{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Prompt_Generator():\n",
    "\n",
    "\n",
    "    def __init__(self, prompt, LLM_Handler, num_datasets = 5 , pval=np.array([0.2, 0.4, 0.6, 0.8])):\n",
    "        \"\"\"\n",
    "         Parameters:\n",
    "        self.original_prompt : original prompt to create subsets\n",
    "        self. pval : distribution P that p is drawn from. Normally  pval=[0.2, 0.4, 0.6, 0.8]\n",
    "        self.num_datasets : Number of datasets or subsets (M in the code) \n",
    "        self.prompts : a list of prompts that are our datasets.\n",
    "            \n",
    "        \"\"\"\n",
    "        self.original_prompt = prompt\n",
    "        self. pval = pval\n",
    "        self.num_datasets = num_datasets\n",
    "        self.sample_prompts = []\n",
    "        self.LLM_Handler = LLM_Handler\n",
    "        # self.prompts.append(self.original_prompt) the original prompt itself isn't something special.\n",
    "\n",
    "\n",
    "    def sample_p(self, size=None):\n",
    "        return np.random.choice(self.pval, size=size)\n",
    "\n",
    "\n",
    "    def coef_scaling(self):\n",
    "        return (1/(self.pval *(1-self.pval))).mean()\n",
    "\n",
    "    def build_vocabulary(self, originalprompt):\n",
    "        \"\"\"\n",
    "        parameter : original prompt\n",
    "\n",
    "        return:\n",
    "        word_to_index : a dic to map words to index inthe original prompt.\n",
    "        unique_words : unique words in the original prompt. If a word is repetitive, the first index will be saved for word_to_index.\n",
    "        N : number of unique words  \n",
    "        \"\"\"\n",
    "        words = re.findall(r'\\b\\w+\\b', originalprompt)\n",
    "        # Step 2: Build the vocabulary\n",
    "        unique_words = []\n",
    "        word_to_index = {}\n",
    "        for word in words:\n",
    "            if word not in word_to_index:\n",
    "                word_to_index[word] = len(unique_words)\n",
    "                unique_words.append(word)\n",
    "\n",
    "        N = len(unique_words)\n",
    "        return word_to_index, unique_words, N\n",
    "    \n",
    "\n",
    "# To Do: resolve the bug that chatgpt doesn't produce exactly that much words.\n",
    "    def create_baseline_words(self):\n",
    "        word_to_index, _, N = self.build_vocabulary(self.original_prompt)\n",
    "        baseline_list = [[] for _ in range(N)]\n",
    "        rng = np.random.default_rng()\n",
    "        num_iterations = 5   #100 *N\n",
    "\n",
    "        for _ in range(num_iterations):\n",
    "            p = np.random.choice(np.array([0.2, 0.4, 0.6, 0.8]))\n",
    "            # print(p)\n",
    "            modified_prompt = remove_words_with_probability(self.original_prompt, probability=p)\n",
    "            # print(modified_prompt)\n",
    "            # Get the LLM to fill in the blanks\n",
    "            filled_prompt = self.LLM_Handler.fill_in_blanks(modified_prompt)\n",
    "            # print(\"filled prompt: \", filled_prompt)\n",
    "            filled_words = re.findall(r'\\b\\w+\\b', filled_prompt)\n",
    "\n",
    "        \n",
    "            modified_words = word_pattern.findall(modified_prompt)\n",
    "            for idx, token in enumerate(modified_words):\n",
    "                if token == '__':\n",
    "                    # print(\"fghj\",filled_words[idx])\n",
    "                    baseline_list[idx].append(filled_words[idx])\n",
    "\n",
    "\n",
    "        \n",
    "        return baseline_list\n",
    "\n",
    "\n",
    "\n",
    "#To Do : might change even before p-featurization\n",
    "    def create_X(self, method='uncompleted'):\n",
    "        self.ps = []\n",
    "        word_to_index, unique_words, N  = self.build_vocabulary(self.original_prompt)\n",
    "        X = np.zeros((self.num_datasets, N)) \n",
    "        nu = self.coef_scaling() # variance of each feature\n",
    "        for m in range(self.num_datasets):\n",
    "            p = self.sample_p()\n",
    "            self.ps.append(p)\n",
    "            modified_prompt = remove_words_with_probability(self.original_prompt, probability= p)\n",
    "            X[m,:] = -1/((1-p)* np.sqrt(nu))\n",
    "            modified_promptWords = re.findall(r'\\b\\w+\\b', modified_prompt)\n",
    "            for modified_word in modified_promptWords:\n",
    "                if modified_word !=\"__\":\n",
    "                    # print(\"we change probability of word: \", modified_word, \"in dataset \", m, \" with index \", word_to_index[modified_word])\n",
    "                    X[m,word_to_index[modified_word]] = 1/(p* np.sqrt(nu))\n",
    "            \n",
    "            # completed_prompt = self.LLM_Handler.fill_in_blanks(modified_prompt)\n",
    "            self.sample_prompts.append(modified_prompt)\n",
    "        return X\n",
    "    \n",
    "    # To Do sample from baseline for each word for putting typical word in it.\n",
    "    def fill_prompt_form_baseline(self, prompts):\n",
    "\n",
    "        return prompts\n",
    "    \n",
    "    \n",
    "    # To do: add the baseline method. Here is just uncompleted.\n",
    "    def create_y(self, prompts, method='uncomplete'):\n",
    "        CLASSIFICATION_PROMPT_Base = \"\"\"You will be given a headline of a news article.\n",
    "        Classify the article into one of the following categories: Technology, Politics, Sports, Art or others.\n",
    "        Return only the name of the category, and nothing else.\n",
    "        MAKE SURE your output is one of the four categories stated.\n",
    "        Article headline: {prompt}\"\"\"\n",
    "\n",
    "        CLASSIFICATION_PROMPT_Method2 = \"\"\"You will be given a headline of a news article with some blanks instead of words.\n",
    "        Classify the article into one of the following categories: Technology, Politics, Sports, Art or others.\n",
    "        Return only the name of the category, and nothing else.\n",
    "        MAKE SURE your output is one of the four categories stated.\n",
    "        Article headline: {prompt}\"\"\"\n",
    "\n",
    "        if method == 'baseline':\n",
    "            baseline_list = self.create_baseline_words()\n",
    "            self.sample_prompts = self.fill_prompt_form_baseline(prompts) #TO Do\n",
    "\n",
    "        y = np.zeros(len(prompts))\n",
    "        outputs = []\n",
    "        for i in range(len(prompts)):\n",
    "            if method=='baseline':\n",
    "                API_RESPONSE = self.LLM_Handler.get_completion(\n",
    "                [{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT_Base.format(prompt=prompts[i])}],\n",
    "                model=\"gpt-4\",\n",
    "                logprobs=True,\n",
    "                top_logprobs=1,\n",
    "                )\n",
    "            elif method =='uncomplete':\n",
    "                API_RESPONSE = self.LLM_Handler.get_completion(\n",
    "                [{\"role\": \"user\", \"content\": CLASSIFICATION_PROMPT_Method2.format(prompt=prompts[i])}],\n",
    "                model=\"gpt-4\",\n",
    "                logprobs=True,\n",
    "                top_logprobs=1,\n",
    "                )\n",
    "\n",
    "\n",
    "            \n",
    "            val = API_RESPONSE.choices[0].logprobs.content[0].top_logprobs[0]\n",
    "            outputs.append(val.token)\n",
    "            y[i] = val.logprob\n",
    "\n",
    "        return y, outputs\n",
    "        \n",
    "    \n",
    "\n",
    "          \n",
    "# Pre-compile regex patterns for efficiency\n",
    "\"\"\"\n",
    "word_pattern matches complete words composed of alphanumeric characters.\n",
    "token_pattern splits the prompt into words, whitespace, and punctuation, ensuring that all characters\n",
    " (including spaces, punctuation like commas and periods, and newlines) are preserved.\n",
    "\"\"\"\n",
    "word_pattern = re.compile(r'\\b\\w+\\b')\n",
    "token_pattern = re.compile(r'\\b\\w+\\b|\\s+|[^\\w\\s]')\n",
    "\n",
    "def remove_words_with_probability(prompt, probability=0.8):\n",
    "    tokens = token_pattern.findall(prompt)\n",
    "    modified_tokens = [\n",
    "        '__' if word_pattern.fullmatch(token) and np.random.uniform(0,1) > probability else token\n",
    "        for token in tokens\n",
    "    ]\n",
    "    return ''.join(modified_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_Handler():\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        load_dotenv('config.env')\n",
    "        openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "    \n",
    "    def fill_in_blanks(self, prompt):\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Please fill in the blanks in the following sentence with exactly one word for each blank then write the sentence with the filled words completely. Remember just sentence without any other thing and the number of filled words equal to the number of blanks.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=500,  \n",
    "                temperature=0,\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            # Extract the assistant's reply from the response\n",
    "            filled_prompt = response['choices'][0]['message']['content'].strip()\n",
    "            return filled_prompt\n",
    "\n",
    "\n",
    "    def get_completion(\n",
    "        self,\n",
    "        messages: list[dict[str, str]],\n",
    "        model: str = \"gpt-4\",\n",
    "        max_tokens=500,\n",
    "        temperature=0,\n",
    "        stop=None,\n",
    "        seed=123,\n",
    "        tools=None,\n",
    "        logprobs=None,  # whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message..\n",
    "        top_logprobs=None,\n",
    "    ) -> str:\n",
    "        params = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"stop\": stop,\n",
    "            \"seed\": seed,\n",
    "            \"logprobs\": logprobs,\n",
    "            \"top_logprobs\": top_logprobs,\n",
    "        }\n",
    "        if tools:\n",
    "            params[\"tools\"] = tools\n",
    "\n",
    "        completion = openai.ChatCompletion.create(**params)\n",
    "        return completion\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__ Mayor __ Initiative to Enhance Urban __ Transport.', 'Local Mayor Launches __ to __ Urban __ __.', 'Local Mayor __ __ to Enhance Urban Public __.', '__ Mayor __ Initiative to __ __ __ __.', 'Local Mayor Launches Initiative __ __ Urban Public __.', '__ Mayor __ Initiative to __ Urban __ Transport.', '__ Mayor Launches __ to __ Urban Public Transport.', 'Local Mayor __ __ to Enhance Urban Public __.', '__ Mayor __ Initiative to Enhance __ __ Transport.', '__ __ __ Initiative to __ Urban __ Transport.', 'Local Mayor Launches Initiative __ __ Urban Public Transport.', '__ Mayor Launches __ __ __ Urban Public __.', 'Local __ Launches Initiative to __ Urban __ Transport.', '__ Mayor Launches __ to Enhance __ Public __.', '__ Mayor Launches Initiative to Enhance Urban __ __.', 'Local Mayor __ __ to __ __ __ __.', '__ __ Launches __ __ __ Urban Public Transport.', 'Local __ __ __ to __ __ __ __.', 'Local __ Launches __ to __ Urban Public __.', '__ Mayor __ Initiative to __ __ __ __.', 'Local Mayor Launches __ to __ Urban __ Transport.', 'Local Mayor __ __ to Enhance Urban Public Transport.', '__ Mayor __ __ __ __ __ Public Transport.', '__ Mayor Launches __ __ Enhance Urban __ Transport.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', 'Local Mayor Launches Initiative to __ Urban __ Transport.', 'Local Mayor Launches Initiative to Enhance Urban __ __.', '__ Mayor __ __ __ Enhance __ Public Transport.', 'Local __ Launches __ to Enhance Urban Public Transport.', 'Local Mayor __ Initiative to Enhance __ Public Transport.', 'Local Mayor __ Initiative to Enhance __ Public Transport.', '__ __ __ __ __ __ __ __ __.', 'Local __ __ __ __ __ __ __ __.', 'Local __ __ __ __ Enhance Urban __ Transport.', '__ __ __ __ __ __ __ __ __.', '__ Mayor Launches Initiative to __ Urban Public Transport.', 'Local Mayor __ __ to Enhance __ __ Transport.', 'Local __ Launches Initiative to __ __ Public Transport.', '__ __ __ __ __ __ __ __ __.', '__ __ __ Initiative to __ Urban __ Transport.', '__ __ __ __ __ __ __ Public __.', 'Local __ Launches Initiative to Enhance Urban Public Transport.', 'Local Mayor Launches Initiative to Enhance __ Public Transport.', 'Local __ Launches Initiative __ Enhance Urban Public Transport.', 'Local __ Launches Initiative __ __ Urban __ __.', '__ Mayor __ __ __ __ __ __ __.', '__ __ __ __ __ __ __ Public __.', 'Local __ Launches Initiative to Enhance Urban Public Transport.', '__ Mayor __ __ __ __ __ __ Transport.', '__ __ Launches __ to Enhance __ Public Transport.', '__ __ __ __ __ __ __ Public __.', 'Local __ __ Initiative __ __ __ __ __.', 'Local Mayor Launches __ to Enhance Urban Public Transport.', '__ __ Launches __ __ __ __ Public __.', '__ __ Launches Initiative __ __ __ __ __.', '__ __ Launches __ __ __ __ __ Transport.', 'Local Mayor Launches Initiative to Enhance __ Public Transport.', '__ Mayor __ __ __ __ __ __ Transport.', 'Local Mayor Launches Initiative to __ Urban Public Transport.', '__ Mayor __ Initiative __ __ __ __ __.', 'Local Mayor Launches Initiative to __ Urban Public Transport.', 'Local Mayor __ Initiative to Enhance Urban Public Transport.', 'Local __ Launches Initiative __ Enhance Urban Public Transport.', '__ Mayor Launches Initiative __ Enhance Urban __ Transport.', '__ __ Launches Initiative __ __ Urban __ __.', 'Local Mayor Launches Initiative to __ Urban Public Transport.', 'Local __ Launches Initiative to Enhance Urban Public __.', '__ __ __ __ to Enhance Urban Public __.', '__ __ __ __ __ Enhance __ __ __.', '__ __ Launches __ to __ __ Public __.', 'Local __ __ __ __ __ __ Public __.', '__ __ __ Initiative __ Enhance Urban Public __.', '__ Mayor Launches __ __ Enhance Urban Public __.', '__ __ __ Initiative __ __ Urban Public __.', '__ __ Launches __ __ __ __ Public Transport.', '__ Mayor Launches __ __ Enhance __ Public Transport.', 'Local __ Launches Initiative __ Enhance Urban __ __.', 'Local __ __ __ __ __ __ __ __.', 'Local __ Launches __ to Enhance Urban Public Transport.', 'Local Mayor Launches __ __ __ __ __ __.', 'Local __ __ __ to Enhance __ Public Transport.', 'Local __ Launches Initiative to Enhance Urban Public __.', '__ Mayor Launches Initiative __ Enhance Urban __ Transport.', 'Local Mayor __ Initiative to Enhance Urban __ Transport.', 'Local Mayor __ Initiative to Enhance __ Public Transport.', '__ Mayor __ __ to __ Urban __ Transport.', 'Local Mayor Launches Initiative __ __ Urban Public Transport.', 'Local __ __ Initiative to Enhance Urban Public Transport.', '__ __ __ __ to Enhance Urban Public Transport.', '__ __ __ __ __ Enhance Urban __ Transport.', '__ __ Launches Initiative to __ __ Public Transport.', '__ __ __ __ __ Enhance __ Public __.', 'Local Mayor Launches Initiative to Enhance Urban Public __.', 'Local Mayor Launches Initiative to Enhance __ Public Transport.', 'Local __ Launches Initiative to Enhance Urban __ __.', '__ __ __ __ __ __ __ __ __.', 'Local Mayor Launches Initiative to Enhance Urban Public __.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', 'Local Mayor Launches Initiative to Enhance Urban Public __.', 'Local Mayor Launches Initiative to __ Urban Public Transport.', 'Local __ __ Initiative to __ Urban Public Transport.', '__ __ __ Initiative __ __ __ __ __.', '__ __ __ Initiative to Enhance Urban Public Transport.', 'Local __ Launches Initiative to __ Urban Public Transport.', '__ __ __ __ __ __ __ __ __.', 'Local __ Launches Initiative __ __ __ __ Transport.', '__ Mayor Launches Initiative to Enhance __ __ __.', 'Local Mayor __ Initiative to Enhance Urban __ Transport.', '__ Mayor Launches Initiative to Enhance __ __ Transport.', 'Local Mayor __ __ to __ Urban __ Transport.', '__ __ __ __ __ __ __ Public __.', '__ Mayor __ __ to __ __ __ Transport.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', '__ __ __ __ to __ __ __ __.', 'Local Mayor Launches Initiative to __ Urban Public Transport.', '__ __ Launches Initiative __ Enhance __ Public Transport.', 'Local __ Launches __ to Enhance Urban Public __.', '__ Mayor Launches __ __ __ __ Public __.', 'Local Mayor Launches __ to Enhance Urban Public Transport.', 'Local Mayor __ Initiative to Enhance Urban __ Transport.', '__ __ __ Initiative __ Enhance __ __ Transport.', 'Local Mayor __ __ to Enhance __ Public __.', 'Local Mayor Launches __ __ Enhance Urban Public Transport.', '__ __ __ __ __ Enhance Urban __ __.', 'Local Mayor Launches Initiative __ Enhance __ Public Transport.', '__ Mayor Launches Initiative to Enhance __ Public Transport.', 'Local Mayor __ Initiative __ Enhance __ __ __.', 'Local Mayor __ Initiative __ __ __ __ Transport.', '__ __ __ Initiative __ Enhance __ __ __.', 'Local __ Launches __ to Enhance Urban __ Transport.', 'Local __ Launches Initiative to __ __ Public __.', 'Local Mayor Launches Initiative __ __ Urban __ Transport.', 'Local __ __ Initiative __ __ Urban __ __.', 'Local Mayor Launches Initiative __ Enhance Urban Public Transport.', '__ __ Launches Initiative __ __ __ __ __.', '__ __ Launches Initiative __ Enhance __ __ __.', 'Local __ __ Initiative to __ Urban __ __.', '__ __ __ Initiative __ __ Urban __ __.', '__ __ __ Initiative __ Enhance __ __ __.', 'Local __ __ Initiative __ __ __ __ __.', 'Local __ __ Initiative to Enhance __ __ __.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', 'Local __ __ Initiative __ __ __ __ __.', '__ __ Launches __ __ __ __ __ __.', '__ __ __ __ __ Enhance __ __ Transport.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', 'Local __ __ Initiative to __ __ Public Transport.', '__ __ Launches __ to __ __ __ Transport.', '__ __ __ __ __ __ __ Public Transport.', 'Local Mayor __ __ __ __ __ __ __.', '__ Mayor Launches __ to __ __ __ __.', 'Local Mayor __ Initiative __ __ Urban Public __.', 'Local Mayor __ Initiative __ Enhance __ __ Transport.', '__ __ __ __ __ __ __ __ __.', '__ __ Launches __ to Enhance Urban Public __.', '__ __ Launches Initiative to Enhance Urban __ __.', '__ __ __ Initiative __ __ Urban Public Transport.', 'Local Mayor Launches __ to Enhance Urban Public Transport.', '__ Mayor Launches __ __ __ Urban __ Transport.', 'Local __ Launches Initiative __ Enhance Urban Public Transport.', 'Local Mayor Launches Initiative to Enhance Urban Public Transport.', 'Local __ Launches __ __ __ __ __ Transport.', '__ __ Launches Initiative __ __ __ __ __.', '__ __ Launches Initiative to __ Urban __ __.', '__ __ Launches Initiative to Enhance __ __ __.', '__ Mayor __ Initiative __ Enhance __ __ __.', 'Local __ Launches Initiative __ Enhance __ Public Transport.', 'Local Mayor Launches Initiative to __ Urban __ __.', 'Local Mayor Launches Initiative to __ __ __ Transport.', 'Local __ __ __ __ __ __ __ __.', '__ Mayor __ __ __ __ __ __ __.', '__ Mayor __ Initiative to Enhance Urban __ __.', '__ __ Launches __ to Enhance Urban Public Transport.', 'Local Mayor __ __ to Enhance __ __ __.', 'Local Mayor Launches __ __ __ Urban __ Transport.', '__ Mayor __ Initiative __ Enhance __ __ __.', '__ Mayor __ __ to __ Urban Public Transport.', '__ Mayor Launches __ __ Enhance Urban Public Transport.', 'Local __ Launches __ to __ Urban Public Transport.', '__ Mayor Launches __ to Enhance __ __ Transport.', 'Local Mayor Launches __ __ Enhance Urban Public Transport.', '__ Mayor Launches __ to Enhance Urban Public Transport.', '__ __ Launches __ __ __ Urban Public Transport.', '__ Mayor __ __ __ __ __ __ Transport.', '__ __ __ __ to __ __ __ __.', '__ __ __ __ __ Enhance Urban Public __.', 'Local Mayor Launches __ __ Enhance __ __ __.', '__ __ Launches __ to __ Urban __ __.', 'Local Mayor Launches Initiative to Enhance __ Public Transport.', '__ __ Launches Initiative to Enhance __ __ Transport.', 'Local __ Launches __ to __ Urban __ Transport.', '__ __ Launches Initiative to __ __ __ Transport.', '__ __ __ Initiative __ __ __ Public __.', '__ __ __ __ __ __ __ __ Transport.', '__ __ __ __ __ Enhance __ __ __.', 'Local Mayor __ __ to __ Urban __ __.', 'Local __ __ __ to Enhance __ __ Transport.', 'Local __ __ __ to Enhance __ Public __.', 'Local Mayor Launches __ to Enhance Urban Public __.', '__ __ __ __ __ __ Urban __ __.']\n",
      "['Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Politics', 'Technology', 'others', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Others', 'Others', 'Technology', 'Others', 'Politics', 'Politics', 'Technology', 'others', 'Technology', 'Others', 'Technology', 'Politics', 'Technology', 'Others', 'Politics', 'Others', 'Technology', 'Politics', 'Technology', 'Others', 'Others', 'Politics', 'Technology', 'Others', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Others', 'Politics', 'Others', 'Technology', 'Technology', 'Technology', 'Others', 'Technology', 'Politics', 'Technology', 'Technology', 'Politics', 'Others', 'others', 'Technology', 'Politics', 'Technology', 'Others', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Technology', 'Technology', 'Technology', 'Technology', 'Politics', 'Politics', 'Others', 'others', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Others', 'Technology', 'Technology', 'Others', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Others', 'Politics', 'Politics', 'others', 'Politics', 'Technology', 'Technology', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Others', 'Technology', 'Others', 'Politics', 'Others', 'Politics', 'Others', 'Others', 'Others', 'Technology', 'Others', 'Others', 'Others', 'Politics', 'Others', 'Technology', 'Technology', 'Politics', 'Technology', 'Technology', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Others', 'Technology', 'Technology', 'Technology', 'Politics', 'Politics', 'Technology', 'Politics', 'Technology', 'Technology', 'Others', 'Technology', 'Politics', 'Technology', 'Politics', 'Politics', 'others', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Politics', 'Politics', 'Technology', 'Politics', 'Others', 'Technology', 'Politics', 'Technology', 'Politics', 'Technology', 'Technology', 'Technology', 'Others', 'Technology', 'Technology', 'Politics', 'Technology', 'Technology', 'Politics', 'Others']\n"
     ]
    }
   ],
   "source": [
    " #  suppose this two words Photo-Editing \n",
    "\n",
    "headlines = [\n",
    "    \"Tech Giant Unveils Latest Smartphone Model with Advanced Photo-Editing Features.\",\n",
    "    \"Local Mayor Launches Initiative to Enhance Urban Public Transport.\",\n",
    "    \"Tennis Champion Showcases Hidden Talents in Symphony Orchestra Debut\",\n",
    "]\n",
    "original_prompt = headlines[1]\n",
    "prompt_generator = Prompt_Generator(prompt=original_prompt, LLM_Handler=LLM_Handler() ,num_datasets = 200 , pval=np.array([0.2, 0.4, 0.6, 0.8]))\n",
    "\n",
    "# word_to_index, _, N = prompt_generator.build_vocabulary(original_prompt)\n",
    "# baseline_list = [[] for _ in range(N)]\n",
    "# rng = np.random.default_rng()\n",
    "# num_iterations = 1\n",
    "\n",
    "# for _ in range(num_iterations):\n",
    "#     p = np.random.choice(np.array([0.2, 0.4, 0.6, 0.8]))\n",
    "#     # print(p)\n",
    "\n",
    "#     modified_prompt = remove_words_with_probability(original_prompt, probability=p)\n",
    "#     # print(modified_prompt)\n",
    "#     # Get the LLM to fill in the blanks\n",
    "#     filled_prompt = prompt_generator.LLM_Handler.fill_in_blanks(modified_prompt)\n",
    "#     # print(\"filled prompt: \", filled_prompt)\n",
    "#     filled_words = re.findall(r'\\b\\w+\\b', filled_prompt)\n",
    "\n",
    " \n",
    "#     modified_words = word_pattern.findall(modified_prompt)\n",
    "#     for idx, token in enumerate(modified_words):\n",
    "#         if token == '__':\n",
    "#             # print(\"fghj\",filled_words[idx])\n",
    "#             baseline_list[idx].append(filled_words[idx])\n",
    "\n",
    "\n",
    "# baseline_list = prompt_generator.create_baseline_words()\n",
    "\n",
    "X = prompt_generator.create_X()\n",
    "print(prompt_generator.sample_prompts)\n",
    "y, outputs = prompt_generator.create_y(prompt_generator.sample_prompts)\n",
    "y = np.round(np.exp(y)*100,5)\n",
    "print(outputs)\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09544512,  0.73029674, -1.09544512, ...,  0.73029674,\n",
       "        -1.09544512,  0.73029674],\n",
       "       [ 0.73029674,  0.73029674,  0.73029674, ...,  0.73029674,\n",
       "        -1.09544512, -1.09544512],\n",
       "       [ 0.73029674,  0.73029674, -1.09544512, ...,  0.73029674,\n",
       "         0.73029674, -1.09544512],\n",
       "       ...,\n",
       "       [ 1.09544512, -0.73029674, -0.73029674, ..., -0.73029674,\n",
       "         1.09544512, -0.73029674],\n",
       "       [ 0.73029674,  0.73029674,  0.73029674, ...,  0.73029674,\n",
       "         0.73029674, -1.09544512],\n",
       "       [-0.73029674, -0.73029674, -0.73029674, ...,  1.09544512,\n",
       "        -0.73029674, -0.73029674]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Mayor Launches Initiative to Enhance Urban Public Transport.\n",
      "Optimal lambda: 0.47148663634573945\n",
      "Coefficients: [-0.          5.8294065  -0.         -1.92589839 -0.          0.\n",
      "  2.7644759   4.05581648  6.48902235]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "alpha_values = np.logspace(-4, 5, 50)\n",
    "lasso_cv = LassoCV(alphas = alpha_values ,cv=5, random_state=123).fit(X, y)\n",
    "print(original_prompt)\n",
    "best_lambda = lasso_cv.alpha_\n",
    "print(\"Optimal lambda:\", best_lambda)\n",
    "\n",
    "# print(\"Coefficients:\", lasso_cv.coef_)\n",
    "\n",
    "print(\"Coefficients:\", lasso_cv.coef_ * np.sqrt(prompt_generator.coef_scaling()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Alpha  Mean_CV_MSE  Std_CV_MSE\n",
      "0  1.000000    38.107172   41.280289\n",
      "1  0.828643    39.268043   41.596831\n",
      "2  0.686649    40.425612   42.138215\n",
      "3  0.568987    42.240030   43.244838\n",
      "4  0.471487    43.992385   44.009362\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Mean MSE across folds for each alpha\n",
    "mse_path_mean = np.mean(lasso_cv.mse_path_, axis=1)\n",
    "# Standard deviation of MSE across folds\n",
    "mse_path_std = np.std(lasso_cv.mse_path_, axis=1)\n",
    "\n",
    "# Corresponding alpha values\n",
    "alphas = lasso_cv.alphas_\n",
    "\n",
    "# Create a DataFrame for easier viewing\n",
    "cv_errors_df = pd.DataFrame({\n",
    "    'Alpha': alphas,\n",
    "    'Mean_CV_MSE': mse_path_mean,\n",
    "    'Std_CV_MSE': mse_path_std\n",
    "})\n",
    "\n",
    "print(cv_errors_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Mean Squared Error (MSE): 22.26310886203446\n",
      "OLS Training Mean Absolute Error (MAE): 3.1960798147776086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X, y)\n",
    "predictions_ols_train = ols_model.predict(X)\n",
    "mse_ols_train = mean_squared_error(y, predictions_ols_train)\n",
    "print(\"OLS Training Mean Squared Error (MSE):\", mse_ols_train)\n",
    "\n",
    "mae_ols_train = mean_absolute_error(y, predictions_ols_train)\n",
    "print(\"OLS Training Mean Absolute Error (MAE):\", mae_ols_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (4.44.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: accelerate in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (0.35.0.dev0)\n",
      "Requirement already satisfied: torch in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hossein rahmani\\pycharmprojects\\causal-llmproject\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 991.5/991.5 kB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers sentencepiece accelerate torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hossein rahmani\\PycharmProjects\\Causal-LLMProject\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\hossein rahmani\\PycharmProjects\\Causal-LLMProject\\.venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hossein rahmani\\PycharmProjects\\Causal-LLMProject\\.venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "load_dotenv('config.env')\n",
    "hf_auth_token  = os.environ.get(\"HF_API_KEY\")\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"  # Example: a restricted-access Llama 3 model\n",
    "\n",
    "# Supply the access token to each from_pretrained call.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    use_auth_token=hf_auth_token\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,  \n",
    "    use_auth_token=hf_auth_token\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
